{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "978b9f40",
   "metadata": {},
   "source": [
    "# AE1 - Working with Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19f6e55",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23149953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and cleaning data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sys\n",
    "import re\n",
    "import requests\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from nltk.corpus import stopwords # Importing stopwords\n",
    "from nltk.tokenize import word_tokenize # Importing the word tokenizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer # VADER Sentiment Analyzer\n",
    "import nltk.data\n",
    "# Download resources for cleaning\n",
    "nltk.download('punkt') # For tokenization\n",
    "nltk.download('stopwords') # For stopwords'\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Import dataset\n",
    "musicDataDF = pd.read_csv('spotify_millsongdata.csv')  \n",
    "\n",
    "# Remove unnecessay columns (link)\n",
    "musicDataDF = musicDataDF.drop(columns=['link'], axis = 1)\n",
    "\n",
    "musicDataDFCleaned = musicDataDF.copy()\n",
    "\n",
    "# Removing special characters, numbers, and unnecessary whitespace for each column and making lowercase\n",
    "for column in list(musicDataDFCleaned.columns.values):\n",
    "    # Only preserve letters and whitespace\n",
    "    musicDataDFCleaned[column] = musicDataDFCleaned[column].str.replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "    # Removing leading or trailing whitespaces\n",
    "    musicDataDFCleaned[column] = musicDataDFCleaned[column].apply(lambda x: x.strip()) \n",
    "    # Normalize all text to lowercase\n",
    "    musicDataDFCleaned[column] = musicDataDFCleaned[column].str.lower() \n",
    "\n",
    "# Removing meaningless words\n",
    "stopwords = stopwords.words('english') #I.e. 'I', 'You', 'Your', etc.\n",
    "stopwords = stopwords + ['refrain', 'chrous', 'verse', 'oh', 'ooh', 'ah', 'im', 'la', 'yeah', 'na', 'dont']\n",
    "\n",
    "def remove_words(text, words_to_remove):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in words_to_remove]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply the remove_words function to the 'lyrics' column\n",
    "musicDataDFCleaned['text'] = musicDataDFCleaned['text'].apply(lambda x: remove_words(x, stopwords))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dafab47",
   "metadata": {},
   "source": [
    "## Analyzing and Visualizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3810b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "artistInput = input(\"Please enter one or more artists (seperated by commas) to view their word usage and general lyrical sentiment. \").lower()\n",
    "\n",
    "# Removes special chars in case user used wrong delimiters\n",
    "bad_chars = [';', ':', \".\", '/','|', ', ']\n",
    "for char in bad_chars:\n",
    "    artistInput = artistInput.replace(char, ',')\n",
    "    \n",
    "artists = artistInput.split(',')   \n",
    "\n",
    "for artist in artists:\n",
    "    if artist not in musicDataDFCleaned['artist'].values:\n",
    "        print(f'Sorry there is no data for {artist}.')\n",
    "        sys.exit()\n",
    "\n",
    "#Initialize the sentiments and the model\n",
    "compound = []\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "#Iterate for each row of lyrics\n",
    "for i in musicDataDFCleaned.index:\n",
    "    # Append the sentiment scores\n",
    "    scores = sid.polarity_scores(musicDataDFCleaned['text'].iloc[i])\n",
    "    compound.append(scores['compound'])\n",
    "    \n",
    "# Classify sentiment based on compound score\n",
    "def categorize_sentiment(compoundScore):\n",
    "    if compoundScore > 0.5:\n",
    "        return 'positive'\n",
    "    elif compoundScore < -0.5:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "    \n",
    "#Create 2 columns to the main dataframe for each score\n",
    "musicDataDFCleaned['compound'] = compound\n",
    "# Classifying song column\n",
    "musicDataDFCleaned['sentiment'] = musicDataDFCleaned['compound'].apply(categorize_sentiment)\n",
    "\n",
    "def get_word_frequency(lyrics):\n",
    "    tokens = word_tokenize(lyrics)\n",
    "    word_freq = Counter(tokens)\n",
    "    return word_freq\n",
    "\n",
    "# Group by artist and aggregate lyrics\n",
    "grouped = musicDataDFCleaned.groupby('artist')['text'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Calculate word frequency\n",
    "word_frequencies = {}\n",
    "for musician, lyrics in grouped.items():\n",
    "    word_frequencies[musician] = get_word_frequency(lyrics)\n",
    "\n",
    "# Printing all output analysis\n",
    "for artist in artists:\n",
    "    # Printing word frequency\n",
    "    wordFreqList = word_frequencies[artist].most_common(10)\n",
    "    vocabRichness = len(word_frequencies[artist])\n",
    "    print(f'\\nThe top 10 most used words by {artist.title()} are: \\n{wordFreqList}')\n",
    "    print(f\"{artist.title()}'s vocabulary richness (unique words used) was {vocabRichness}\")\n",
    "    \n",
    "    # wordCloud initialization\n",
    "    wordcloud = WordCloud(width = 200, height = 200,\n",
    "                background_color ='white',\n",
    "                min_font_size = 5).generate(grouped.loc[artist])\n",
    "\n",
    "    # plot the WordCloud image                       \n",
    "    plt.figure(figsize = (4, 4), facecolor = None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad = 0)\n",
    "    plt.show()\n",
    "    \n",
    "    # Histogram to accompany wordcloud\n",
    "    words = [tup[0] for tup in wordFreqList]\n",
    "    frequencies = [tup[1] for tup in wordFreqList]\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.bar(words, frequencies)\n",
    "    plt.xlabel('Words')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Word Frequency Histogram')\n",
    "    plt.xticks(rotation=90)  \n",
    "    plt.tight_layout()  \n",
    "    plt.show()\n",
    "    \n",
    "    # Filter the DataFrame for the specific artist\n",
    "    artist_df = musicDataDFCleaned[musicDataDFCleaned['artist'] == artist]\n",
    "\n",
    "    # Count sentiment scores for the specific artist\n",
    "    sentimentScores = artist_df['sentiment'].value_counts()\n",
    "    print(f\"\\nThe sentiments for {artist.title()}'s songs are: \\n{sentimentScores}\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    sentimentScores.plot(kind='bar', color='skyblue')\n",
    "    \n",
    "    plt.title('Number of Songs by Sentiment')\n",
    "    plt.xlabel('Sentiment')\n",
    "    plt.ylabel('Song Count')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726dcdf1",
   "metadata": {},
   "source": [
    "### Comparing Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4744c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of the artists\n",
    "print('Comparing artists:')\n",
    "overlapWordList = []\n",
    "artistWordFreqDict = {}\n",
    "artistSentimentScoreDict = {}\n",
    "\n",
    "# Initalizing the respective sentiment scores and word frequency lists\n",
    "for artist in artists:\n",
    "    # Filling artist and word frequency dict\n",
    "    artistWordFreqDict[artist] = word_frequencies[artist].most_common(10)\n",
    "    overlapWordList = [item[0] for item in artistWordFreqDict[artist]] # Initalizes list so when the intersection is taken, the list is not empty\n",
    "    \n",
    "    # Sentiment scores\n",
    "    artist_df = musicDataDFCleaned[musicDataDFCleaned['artist'] == artist]\n",
    "    artistSentimentScoreDict[artist] = artist_df['sentiment'].value_counts()\n",
    "\n",
    "# Taking the intersection of word freq lists to print overlap\n",
    "for artist, wordFreq in artistWordFreqDict.items():\n",
    "    # Taking just the values of the word frequency lists\n",
    "#     overlapWordList = [item[0] for item in overlapWordList]\n",
    "    wordFreq = [item[0] for item in wordFreq]\n",
    "    \n",
    "    # Taking intersection\n",
    "    overlapWordList = set(overlapWordList).intersection(wordFreq)\n",
    "    \n",
    "if len(overlapWordList) > 0:\n",
    "    print(f'The overlapping commonly used words between your artists are: {overlapWordList}')\n",
    "else:\n",
    "    print(\"There were no overlapping commonly used words between your artists\")\n",
    "    \n",
    "# Visualizing overlap\n",
    "\n",
    "# Extract words and counts from the lists\n",
    "words1, counts1 = zip(*artistWordFreqDict[artists[0]])\n",
    "words2, counts2 = zip(*artistWordFreqDict[artists[1]])\n",
    "\n",
    "# Create a set of all unique words\n",
    "all_words = set(words1).union(set(words2))\n",
    "\n",
    "# Create a matrix\n",
    "matrix = np.zeros((len(all_words), len(all_words)))\n",
    "\n",
    "# Fill in the matrix with counts\n",
    "for i, word1 in enumerate(all_words):\n",
    "    for j, word2 in enumerate(all_words):\n",
    "        count1 = counts1[words1.index(word1)] if word1 in words1 else 0\n",
    "        count2 = counts2[words2.index(word2)] if word2 in words2 else 0\n",
    "        matrix[i][j] = count1 + count2\n",
    "\n",
    "# Create a heatmap\n",
    "sns.set(font_scale=0.5)\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.heatmap(matrix, annot=True, fmt='g', cmap='YlGnBu', xticklabels=list(all_words), yticklabels=list(all_words))\n",
    "plt.xlabel(f'Lyrics for {artists[0].title()}')\n",
    "plt.ylabel(f'Lyrics for {artists[1].title()}')\n",
    "plt.title('Heatmap of Word Frequency Counts')\n",
    "plt.show()\n",
    "    \n",
    "# Analzying the correlation of sentiment values\n",
    "if len(artists) == 2: # Only works if user inputted 2 artists\n",
    "    correlationValue = artistSentimentScoreDict[artists[0]].corr(artistSentimentScoreDict[artists[1]])\n",
    "    if correlationValue > 0.4:\n",
    "        print(f'Your artists have a very similar sentiment score. In fact, their correlation is {round(correlationValue, 2)}')\n",
    "    elif correlationValue > -0.4:\n",
    "        print(\"There is no strong correlation between your artists' sentiment scores\")\n",
    "    else:\n",
    "        print(f'Your artists have an opposite sentiment score. In fact, their correlation is {round(correlationValue, 2)}')\n",
    "else:\n",
    "    print(\"Only enter 2 artists if you want to see their sentiment score correlation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d97b2",
   "metadata": {},
   "source": [
    "## Lyric Generation - N-gram and Markov Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0b575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markov Chaining Lyric Generation\n",
    "\n",
    "# Cleaning data in different fashion\n",
    "\n",
    "# List of String Columns\n",
    "string_columns = musicDataDF.select_dtypes(include='object').columns\n",
    "string_columns.to_list()\n",
    "\n",
    "# Removing special characters, numbers, and unnecessary whitespace for each column and making lowercase\n",
    "for column in string_columns:\n",
    "    # Only preserve letters and whitespace\n",
    "    musicDataDF[column] = musicDataDF[column].str.replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "    # Removing leading or trailing whitespaces\n",
    "    musicDataDF[column] = musicDataDF[column].apply(lambda x: x.strip()) \n",
    "    \n",
    "musicDataDF['artist'] = musicDataDF['artist'].str.lower() \n",
    "    \n",
    "artistInput = input(\"Please enter one or more artists (seperated by commas) to generate a new song for. \").lower()\n",
    "\n",
    "# Removes special chars in case user used wrong delimiters\n",
    "bad_chars = [';', ':', \".\", '/','|', ', ']\n",
    "for char in bad_chars:\n",
    "    artistInput = artistInput.replace(char, ',')\n",
    "    \n",
    "artists = artistInput.split(',')\n",
    "for artist in artists:\n",
    "    if artist not in musicDataDFCleaned['artist'].values:\n",
    "        print(f'Sorry there is no data for {artist}.')\n",
    "        sys.exit()\n",
    "        \n",
    "# Not using the cleaned version because we need all lyrics for generation\n",
    "groupedAllLyrics = musicDataDF.groupby('artist')['text'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Gathering all lyrics\n",
    "totalLyrics = ''\n",
    "for artist in artists:\n",
    "    totalLyrics += (\" \" + groupedAllLyrics.loc[artist])\n",
    "\n",
    "totalLyrics = totalLyrics.split() \n",
    "\n",
    "markovOrN_Gram = input('Would you like a Markov Chaining based song or N-Gram based song? ').lower()\n",
    "numOfSongs = int(input('Please enter how many songs you want produced. '))\n",
    "songLength = int(input('Please enter how many words you want your songs to be. '))\n",
    "\n",
    "\n",
    "if 'markov' in markovOrN_Gram: # Markov chaining method\n",
    "\n",
    "    def nextWord(currentSong, lyricBank):\n",
    "        nextOptions = []\n",
    "        for i in range(len(currentSong)):\n",
    "            for j in range(len(lyricBank)):\n",
    "                if lyricBank[j:j+i+1] == currentSong[(0-i)-1:]:\n",
    "                    try:\n",
    "                        nextOptions.append(lyricBank[j + 1]) # Error catching for indexOutOfBounds. In case the word of the song being tested is the last word in lyricBank\n",
    "                    except IndexError:\n",
    "                        nextOptions.apppend('oh') # Filler\n",
    "        return str((np.random.choice(nextOptions)))\n",
    "\n",
    "    for i in range(numOfSongs):\n",
    "        print(f'Song {i+1}:')\n",
    "        first_word = np.random.choice(totalLyrics)\n",
    "\n",
    "        while first_word.islower():\n",
    "            first_word = np.random.choice(totalLyrics)\n",
    "\n",
    "        chain = [first_word]\n",
    "\n",
    "        n_words = songLength\n",
    "\n",
    "        for i in range(n_words):\n",
    "            newWord = nextWord(chain, totalLyrics)\n",
    "            if newWord != newWord.lower() and newWord != 'I':\n",
    "                chain.append(\"\\n\")\n",
    "            chain.append(newWord)\n",
    "\n",
    "        print(' '.join(chain))\n",
    "        print('\\n')\n",
    "\n",
    "else:\n",
    "    numOfGrams =int(input('Please enter how many grams you want used. '))\n",
    "    \n",
    "    # Starting words, that would not be capital anyway\n",
    "    seeds = [word for word in totalLyrics if word.istitle() and word not in [\"I\", \"Id\", \"Ive\", \"God\"]]\n",
    "\n",
    "    def nGrams(words, n):\n",
    "        ngramDict = {}\n",
    "\n",
    "        # Generate n-grams\n",
    "        for i in range(len(words) - n):\n",
    "            keyWord = words[i]\n",
    "            nextNgram = tuple(words[i+1:i+n+1])\n",
    "\n",
    "            if keyWord in ngramDict:\n",
    "                ngramDict[keyWord].append(nextNgram)\n",
    "            else:\n",
    "                ngramDict[keyWord] = [nextNgram]\n",
    "\n",
    "        return ngramDict\n",
    "    \n",
    "        \n",
    "    def generateSong(seeds, songLength, ngrams):\n",
    "        sentence = \"\"\n",
    "        curr_word = str(random.choice(seeds))\n",
    "        wordCount = 1\n",
    "        while wordCount < songLength:\n",
    "            \n",
    "            nextTuple = random.choice(ngrams[curr_word])\n",
    "            if nextTuple[0] != nextTuple[0].lower():\n",
    "                sentence += '\\n'\n",
    "            nextStr = ' '.join(nextTuple)\n",
    "            sentence = sentence + ' ' + nextStr\n",
    "            \n",
    "            wordCount += 1\n",
    "        return sentence\n",
    "    \n",
    "    for i in range(numOfSongs): \n",
    "        print(f'Song {i+1}:')\n",
    "        print(generateSong(seeds, songLength, nGrams(totalLyrics, numOfGrams)))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99516877",
   "metadata": {},
   "source": [
    "## Above and Beyond"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d88d89",
   "metadata": {},
   "source": [
    "### Song recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e734b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Song recommender\n",
    "\n",
    "# based on key words, sentiments of inputted song(s)\n",
    "print('Please format your responce like: Bang by Abba, Hammer to Fall by Queen, etc.')\n",
    "songsAndArtists = input('Please input one or more songs and their artists you like to recieve similar recommendations. ').lower()\n",
    "\n",
    "# Removes special chars in case user used wrong delimiters\n",
    "bad_chars = [';', ':', \".\", '/','|', ', ']\n",
    "for char in bad_chars:\n",
    "    songsAndArtists = songsAndArtists.replace(char, ',')\n",
    "\n",
    "# Creating an empty dictionary with song, artist pairs\n",
    "songsAndArtists = songsAndArtists.split(',')\n",
    "songsDict = {}\n",
    "\n",
    "# Iterate over each pair, split it by 'by' and store in the dict\n",
    "for pair in songsAndArtists:\n",
    "    song, artist = pair.split(' by ')\n",
    "    # check validity\n",
    "    if (artist not in musicDataDFCleaned['artist'].values) or (song not in musicDataDFCleaned['song'].values):\n",
    "        print(f'Sorry there is no data for that song.')\n",
    "        sys.exit()\n",
    "    songsDict[song] = artist\n",
    "\n",
    "# Get top 15 most common words from a string\n",
    "def get_top_15_words(words):\n",
    "    word_counts = Counter(words)\n",
    "    # Get the top 15 most common words\n",
    "    top_15_words = word_counts.most_common(15)\n",
    "    # Return only the words, not the counts\n",
    "    return top_15_words\n",
    "\n",
    "# Creating new column with the top 15 words used in each song\n",
    "musicDataDFCleaned['top words'] = musicDataDFCleaned['text'].apply(lambda x: get_top_15_words(x.split()))\n",
    "\n",
    "sentimentScores = []\n",
    "commonWords = []\n",
    "\n",
    "# Checking what sentiment to look for\n",
    "for song, artist in songsDict.items():\n",
    "    rowIndex = (musicDataDFCleaned['song'] == song) & (musicDataDFCleaned['artist'] == artist)\n",
    "    desiredRow = musicDataDFCleaned[rowIndex]\n",
    "    sentimentScores.append(desiredRow['sentiment'].values)\n",
    "    commonWords = commonWords + list(desiredRow['top words'].values[0])\n",
    "\n",
    "# get most common sentiment\n",
    "def getSentiment(sentimentsList):\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    neu = 0\n",
    "    for sent in sentimentsList:\n",
    "        if sent == 'positive':\n",
    "            pos += 1\n",
    "        elif sent == 'negative':\n",
    "            neg += 1\n",
    "        else:\n",
    "            neu += 1\n",
    "    if pos > neg:\n",
    "        return 'positive'\n",
    "    elif neg > pos:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# check overlapping words between artists\n",
    "def numOverlappingWords(setWords, wordsToCompare):\n",
    "    intersection = list(set(setWords) & set(wordsToCompare))\n",
    "    return len(intersection)\n",
    "\n",
    "sentiment = getSentiment(sentimentScores)\n",
    "maxWordOverlap = 0\n",
    "currentSong = ''\n",
    "currentArtist = ''\n",
    "\n",
    "for index, row in musicDataDFCleaned.iterrows():\n",
    "    if row['sentiment'] == sentiment: # if the artist's sentiments match\n",
    "        if numOverlappingWords(commonWords, row['top words']) > maxWordOverlap and row['song'] not in songsDict:\n",
    "            maxWordOverlap = numOverlappingWords(commonWords, row['top words'])\n",
    "            currentSong = row['song']\n",
    "            currentArtist = row['artist']\n",
    "\n",
    "print(f'I recommend listening to {currentSong.title()} by {currentArtist.title()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6731f0a8",
   "metadata": {},
   "source": [
    "### Adding Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cac83cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Data\n",
    "albumDataDF = pd.read_csv('albumsSold.csv')\n",
    "\n",
    "# Cleaning Data\n",
    "albumDataDF = albumDataDF.drop(columns=['Artist ID'], axis = 1) # Remove unnecessay column\n",
    "albumDataDF['Artist'] = albumDataDF['Artist'].str.lower() # Making artist name lowercase\n",
    "albumDataDF.rename(columns={'Artist': 'artist'}, inplace=True)\n",
    "# Changing Datatype\n",
    "columnsConvert = ['Certified Units', 'Gold', 'Platinum', 'Multi-Platinum', 'Diamond']\n",
    "albumDataDF[columnsConvert] = albumDataDF[columnsConvert].astype(int)\n",
    "\n",
    "# Merging Dataframes\n",
    "musicAndAlbumsDF = pd.merge(musicDataDFCleaned, albumDataDF, on='artist', how='inner')\n",
    "\n",
    "# Get sum of albums sold for each sentiment score\n",
    "sentiment_counts = musicAndAlbumsDF['sentiment'].value_counts()\n",
    "sentimentAlbumsGrouped = musicAndAlbumsDF.groupby('sentiment')['Certified Units'].sum().reset_index()\n",
    "\n",
    "# Normalize albums sold by the total count of songs for each sentiment category\n",
    "sentimentAlbumsGrouped['normalizedAlbumsSold'] = sentimentAlbumsGrouped.apply(lambda row: row['Certified Units'] / sentiment_counts[row['sentiment']], axis=1)\n",
    "\n",
    "correlation_coefficient = np.corrcoef(sentiment_counts.values[::-1], sentimentAlbumsGrouped['normalizedAlbumsSold'].values)[0, 1]\n",
    "\n",
    "# Plot the barchart and correlation \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=sentimentAlbumsGrouped, x='sentiment', y='normalizedAlbumsSold', palette='coolwarm')\n",
    "plt.title(f'Correlation between Sentiment Score Value Counts and Albums Sold \\nCorrelation Coefficient: {correlation_coefficient:.2f}', fontsize = 11)\n",
    "plt.xlabel('Sentiment Score', fontsize = 9)\n",
    "plt.ylabel('Normalized Albums Sold', fontsize = 9)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bbf12c",
   "metadata": {},
   "source": [
    "## Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc2d81d",
   "metadata": {},
   "source": [
    "I really enjoyed completing this project. It was interesting to compare the sentiment scores and word usage from different artists, particularly across genres. It was also fun to see lyric generation and song recommendations. I listened to the recommendations against the compared song and actually found them to be very similar. It was gratifying to see successful results from a simple idea (comparing sentiment scores and vocabulary richness/usage).\n",
    "\n",
    "The main challenge I encountered during the project was dealing with complicated data structures. Throughout the project, I used layers of abstraction to create efficient code at the expense of readability and simplicity. For example, I created a dictionary with a list full of tuples as values. Therefore, I had to index 4 times to get the value with the tuple. This strategy has fast lookup time but was slightly confusing to code and produced many Index and Type Errors.\n",
    "\n",
    "To solve this, I clearly outlined my code with comments and printed each 'type' of data structure throughout my code for debugging purposes. This helped me understand the different object types I was using and gave me ideas on how to solve other problems based on their unique qualities. For example, when finding the number of overlapping words between 2 songs, I realized I had 2 lists in the dataframe of the top words. So, I could use the built-in 'intersection' method to find the overlap. 'Intersection' returns another list, so I could simply return the 'len' of the result to find the number of overlapping words. This task may not have been as easy if I was using numpy arrays or a queue/stack. Furthermore, when determining vocabulary richness, I realized my dictionary with words as keys and their frequencies as values was also the length of all unique words so I could use the 'len' function again.\n",
    "\n",
    "Throughout the project, I learned to write more generalized code. Early on, I was struggling to write code that could work for any number of artists and was hard-coding solutions with the prior knowledge that I would likely have 2 artists as input. However, as I kept working, I discovered techniques (like using dictionaries within for each loops) to generalize my code (comparison, lyric generation, and song recommendation) to work for any number of artists or songs.\n",
    "\n",
    "I also learned to take a wholly different approach when debugging rather than making small changes. For example, the n-gram method of lyric generation produced somewhat incomprehensible songs, so instead of trying to optimize it I implemented a Markov chaining method of lyric generation. I also believe it makes slightly better songs because it does not get 'stuck' in loops or repeat lyrics as often as n-grams.\n",
    "\n",
    "For future iterations of this project, I would recommend adding web-scraping as an aspect to look for more information on each artist. I briefly attempted to implement it to check for artist's lyrics that were not in the dataset. I was able to scrape age for individual artists off Wikipedia, but unfortunately, I could not find a generalized site with extensive data that I could use for any artist, so it didn't work well enough. However, in the future, perhaps there could be a site that finds the genre, age, ethnicity, usual tempo, etc. of the artist so there is more data to compare them.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
